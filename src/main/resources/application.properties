spring.application.name=spring-ai-knowledge-base
server.port=8080

# Activate Postgres-backed vector store by default
spring.profiles.active=pg

# Logging
logging.level.root=INFO
logging.level.com.wantwant.sakb=DEBUG

# Springdoc
springdoc.api-docs.enabled=true
springdoc.swagger-ui.enabled=true

# ===== Multipart (increase upload limits) =====
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=60MB
# Optional: allow large swallow to avoid connection reset on oversized payloads
server.tomcat.max-swallow-size=100MB

# ===== Local database (Postgres + pgvector) =====
spring.datasource.url=jdbc:postgresql://localhost:5432/sakb
spring.datasource.username=sakb
spring.datasource.password=sakb
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=false

# Initialize schema (pgvector extension and tables)
spring.sql.init.mode=always
spring.sql.init.schema-locations=classpath:db/pgvector-init.sql

# Embedding vector dimension (must match DB column VECTOR(..) size)
kb.vector.dim=1536

# ===== Local AI model (Ollama) =====
# Ollama base URL (docker-compose exposes 11434)
spring.ai.ollama.base-url=http://localhost:11434
# Explicitly enable Ollama auto-config
spring.ai.ollama.enabled=true
spring.ai.ollama.chat.enabled=true
spring.ai.ollama.embedding.enabled=true
# Default local chat model (adjust as you like)
spring.ai.ollama.chat.options.model=deepseek-r1:1.5b
# Default local embedding model
spring.ai.ollama.embedding.options.model=bge-m3:latest

# ===== OpenAI disabled by default =====
# AI provider placeholders (enable via env/profile if you want OpenAI)
# openai.api-key=
# spring.ai.openai.chat.options.model=gpt-4o-mini
# spring.ai.openai.embedding.options.model=text-embedding-3-small

spring.ai.openai.enabled=false
spring.ai.openai.speech.enabled=false

# Exclude OpenAI auto-configs so app boots without OpenAI
spring.autoconfigure.exclude=org.springframework.ai.model.openai.autoconfigure.OpenAiAudioSpeechAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiAudioTranscriptionAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiChatAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiEmbeddingAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiImageAutoConfiguration,org.springframework.ai.model.openai.autoconfigure.OpenAiModerationAutoConfiguration

# ===== Actuator exposure for diagnostics =====
management.endpoints.web.exposure.include=health,info,beans,conditions,env

# ===== Dify (optional integration) =====
# Enable to expose /api/dify endpoints
# dify.enabled=false
# dify.api-key=
# dify.base-url=https://api.dify.ai
# dify.workflow-id=
# dify.dataset-id=
# dify.timeout-ms=10000
# dify.sync-enabled=false
